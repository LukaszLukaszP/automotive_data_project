# Automotive Data Project

This project is an extensible, end-to-end automotive data pipeline built in Python. It is designed to collect, clean, enrich, and store car listing data â€” currently from [Otomoto.pl](https://otomoto.pl) â€” in a structured PostgreSQL database. Future plans include advanced analytics, ML/AI modules, dashboard visualizations, and integration with conversational AI.

---

## ðŸš— Features

* **Web scraping** with anti-duplicate logic
* **Dynamic listing segmentation** to avoid pagination limits
* **Data cleaning & transformation** including units, types, and missing values
* **Equipment parsing & normalization**
* **PostgreSQL schema creation and data loading**
* **Modular architecture** ready for additional sources and ML/AI features

---

## ðŸ—‚ Project Structure

```text
.
â”œâ”€â”€ data/                  # CSV exports, IDs, model mappings
â”œâ”€â”€ notebooks/            # Jupyter Notebooks (EDA, cleaning, legacy steps)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraping_otomoto_skip_duplicates_V1.py   # Main scraping logic
â”‚   â”œâ”€â”€ merge_csvs.py                            # Merge raw data files
â”‚   â”œâ”€â”€ split_data_for_postgres.py               # Cleaning + final CSVs for SQL
â”‚   â”œâ”€â”€ append_data.py                           # Insert into PostgreSQL
â”‚   â”œâ”€â”€ init_db.py                               # DB schema + views
â”‚   â”œâ”€â”€ makes_and_models_scraping.py             # Otomoto brands & models
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ data_cleaning_utils.py               # Specialized cleaning functions
â”‚       â””â”€â”€ equipment_utils.py                   # Equipment parsing utilities
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ðŸ§ª Technologies Used

* Python 3.10+
* `requests`, `BeautifulSoup` (web scraping)
* `pandas`, `numpy` (data processing)
* `SQLAlchemy`, `psycopg2` (PostgreSQL connection)
* `selenium` (dynamic scraping for brand/model data)
* PostgreSQL 13+

---

## ðŸ§¹ Data Flow Overview

1. **Scraping Otomoto:**

   * Script: `scraping_otomoto_skip_duplicates_V1.py`
   * Output: `data/all_offers_otomoto_no_vin_*.csv`
   * Avoids duplicates using tracked `advert_id`s

2. **Merging and Cleaning:**

   * `merge_csvs.py` â†’ merges raw CSVs
   * `split_data_for_postgres.py` â†’ cleans fields, renames columns, builds equipment mapping
   * Outputs: `listings.csv`, `equipment_options.csv`, `listing_equipment.csv`

3. **PostgreSQL Storage:**

   * `init_db.py` creates schema
   * `append_data.py` loads clean data into the database, remapping `local_id` to real primary keys

---

## âš™ï¸ How to Run

> Project is under active development. Environment setup will be simplified soon.

### 1. Set up a virtual environment

```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Configure PostgreSQL (local)

Make sure your PostgreSQL server is running and update the connection string if needed.

### 3. Run pipeline steps manually:

```bash
python scripts/scraping_otomoto_skip_duplicates_V1.py
python scripts/merge_csvs.py
python scripts/split_data_for_postgres.py
python scripts/init_db.py
python scripts/append_data.py
```

> You can use Jupyter Notebooks for data exploration under `notebooks/`.

---

## ðŸ“Œ Plans & Roadmap

### ðŸ”§ Short-term goals (next steps)
- [ ] Refactor scraping script to capture all relevant columns
- [ ] Improve error handling and logging in scraper
- [ ] Standardize and validate all units and column names
- [ ] Create interactive data exploration dashboard (Streamlit or Dash)

### ðŸ“Š Mid-term goals
- [ ] Support additional data sources
- [ ] Design PostgreSQL views for easier querying
- [ ] Add unit tests for cleaning and merging logic

### ðŸ§  Long-term / AI-focused goals
- [ ] Build ML model for price prediction based on vehicle attributes
- [ ] Implement classification of listings (e.g., by condition, seller type)
- [ ] Add car recommendation engine (based on user preferences)
- [ ] Integrate chatbot (LLM-based) to query listings or explain trends

### âš™ï¸ Deployment / UX ideas
- [ ] Expose API endpoints for filtered car search
- [ ] Package scraping and cleaning as CLI tool or service
- [ ] Containerize full pipeline using Docker


---

## ðŸ“‚ Datasets

* Raw data is ignored in `.gitignore` due to size (>100 MB per file)
* Example mappings (`brands_and_models.csv`, `equipment_options.csv`) included
* To run full pipeline, scrape your own data or request access to anonymized sample